分割句子的方法:
使用sent_tokenize 是 NLTK（自然語言工具包）中的一個函數，用於將文本分割成句子。其實現主要依賴於 Punkt 分句器，
結合了 規則基礎（rule-based）方法 和統計模型（statistical model）的混合方法。

Punkt 分句器模型
Punkt 分句器通過分析大量未標註的文本數據，學習標點符號（如句號、問號、感嘆號）在不同上下文中的使用模式，以辨識句子邊界。

但它也利用了多種基於規則的策略來處理特定情境，尤其是在處理縮寫、標點符號和其他潛在的句子結束標誌時。
1.使用了一系列規則來識別縮寫，避免將縮寫中的句點（如 "Dr."、"e.g."、"Mr." 等）誤認為句子的結束符號。
2.使用基於上下文的規則來決定標點符號是否表示句子結束。ex：當標點符號（如句點）後跟著大寫字母時，這通常被認為是句子的結束。
    如果標點符號後面是數字或小寫字母，則 Punkt 會根據這些模式決定是否繼續分句，還是將其視為縮寫的一部分
3.處理數字和標點符號組合，像日期或數字中的句號（例如 "12.08.2024"）
4.詞頻和標點符號規則，句號、問號、感嘆號這些標點符號往往出現在句子末尾

========================================================================================================================

製作一個搜尋引擎UI介面，包含以下功能：

1. 字數統計：
可計算 keywords 數量、characters (including spaces)、characters (excluding spaces)、words、sentences、non-ASCII characters、non-ASCII words。

2. 上傳XML資料：
UI介面需具備上傳XML資料的功能，使用者能夠直接將XML檔案上傳並進行搜尋。

3. 搜尋欄：
提供一個搜尋欄，使用者可輸入欲搜尋的關鍵字或短語。

4. 搜尋選項：
應具備多種搜尋選項，允許使用者設定搜尋範圍或過濾條件。

5. 查看儲存資料：
使用者可以在介面中查看已儲存的搜尋結果或已上傳的資料。